{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#获取“说”的同义词\" data-toc-modified-id=\"获取“说”的同义词-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>获取“说”的同义词</a></span></li><li><span><a href=\"#匹配:-人名-+-“说”+“，”-+话+-句号结尾\" data-toc-modified-id=\"匹配:-人名-+-“说”+“，”-+话+-句号结尾-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>匹配: 人名 + “说”+“，” +话+ 句号结尾</a></span></li><li><span><a href=\"#补充匹配：话+“，”+人名+“说”+“。”\" data-toc-modified-id=\"补充匹配：话+“，”+人名+“说”+“。”-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>补充匹配：话+“，”+人名+“说”+“。”</a></span></li><li><span><a href=\"#尚未匹配：话1+人名+“说”+话2\" data-toc-modified-id=\"尚未匹配：话1+人名+“说”+话2-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>尚未匹配：话1+人名+“说”+话2</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获取“说”的同义词\n",
    "> 找到言论提出者和言论部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Christopher_luole\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load wiki valid-tokens in Assignment2\n",
    "# Read all Tokens files into ALL_TOKENS\n",
    "def Read_Tokens(path):\n",
    "    \"\"\"\n",
    "    input: path of Tokens files\n",
    "    output: list of valid tokens\n",
    "    \"\"\"\n",
    "    with open(path,'r',encoding=\"utf-8\") as file:\n",
    "        ALL_TOKENS = file.read()\n",
    "        ALL_TOKENS = ALL_TOKENS.replace(\"'\",\"\").replace(\"[\",\"\").replace(\"]\",\"\").split(', ')\n",
    "        valid_tokens = [t for t in ALL_TOKENS if t.strip()]\n",
    "    return valid_tokens\n",
    "\n",
    "from time import time\n",
    "import os\n",
    "path_AA = os.getcwd()+\"\\\\mydata\\\\text\\\\AA\"\n",
    "path_AB = os.getcwd()+\"\\\\mydata\\\\text\\\\AB\"\n",
    "\n",
    "def get_file_name(path):\n",
    "    \"\"\"\n",
    "    input: string, file path, like'C:\\\\Users\\\\Christopher_luole\\\\Git_Project\\\\mydata\\\\text\\\\AA'\n",
    "    output: list, with all visible file name under the path\n",
    "    \"\"\"\n",
    "    list_of_file_name = []\n",
    "    for file_name in os.listdir(path):\n",
    "        if not file_name.startswith('.'):\n",
    "            list_of_file_name.append(file_name) \n",
    "    return list_of_file_name\n",
    "\n",
    "AA = get_file_name(path_AA)\n",
    "AB = get_file_name(path_AB)\n",
    "\n",
    "valid_tokens = []\n",
    "for file in AA:\n",
    "    start=time()\n",
    "    valid_tokens += (Read_Tokens(path_AA[:-7]+\"Tokens\\\\AA\\\\\"+file+\".txt\"))\n",
    "    T1=time()-start\n",
    "    #print(\"Add {} in AA, and Length of valid_tokens increased to {}, spend {} seconds\".format(file, len(valid_tokens),T1))\n",
    "\n",
    "for file in AB:\n",
    "    start=time()\n",
    "    valid_tokens += (Read_Tokens(path_AB[:-7]+\"Tokens\\\\AB\\\\\"+file+\".txt\"))\n",
    "    T1=time()-start\n",
    "    #print(\"Add {} in AB, and Length of valid_tokens increased to {}, spend {} seconds\".format(file, len(valid_tokens),T1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 28328816/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_tokens_sentence = [valid_tokens[i*1000 : (i+1)*1000] for i in range(28328)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28328"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_tokens_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time spend: 200 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "model2 = Word2Vec(valid_tokens_sentence)\n",
    "T = time()-start\n",
    "print(\"Total time spend: {} seconds\".format(round(T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Word2Vec.save(model2, \"model_wiki_word2vec_1000words_per_sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2 = Word2Vec.load(\"mydata\\model_wiki_word2vec_1000words_per_sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('显示', 0.7021205425262451),\n",
       " ('指出', 0.6783677935600281),\n",
       " ('说明', 0.6592695713043213),\n",
       " ('证实', 0.6343373656272888),\n",
       " ('证明', 0.6269102096557617),\n",
       " ('断定', 0.6219356060028076),\n",
       " ('声称', 0.5971212387084961),\n",
       " ('推断', 0.5962259769439697),\n",
       " ('宣称', 0.5861431360244751),\n",
       " ('表示', 0.5734509229660034)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar('表明')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = [model2.most_similar(\"说\", topn = 100)[i][0] for i in range(100)]\n",
    "c = [model2.most_similar(\"认为\", topn = 100)[i][0] for i in range(100)]\n",
    "e = [model2.most_similar(\"表明\", topn = 100)[i][0] for i in range(100)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 得到想要的近义词了，以上代码不需要再run了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 手动筛选一遍后留下以下“说”的近义词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "similars = pd.read_csv(\"similar_said.csv\", encoding = \"gbk\")#total 117 similar words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "said_list = list(similars['similar_of_said'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 匹配: 人名 + “说”+“，” +话+ 句号结尾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = \"\"\"新华社华盛顿4月26日电 美国总统特朗普26日表示，美国将撤销在《武器贸易条约》上的签字。\n",
    "\n",
    "特朗普当天在美国印第安纳州首府印第安纳波利斯举行的美国全国步枪协会年会上说，《武器贸易条约》是一个“严重误导的条约”，美国将撤销在该条约上的签字，联合国将很快收到美国正式拒绝该条约的通知。\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from jieba import posseg# use jieba package to do Name Entity Recoginition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['新华社华盛顿4月26日电 美国总统特朗普26日表示，美国将撤销在《武器贸易条约》上的签字',\n",
       " '\\n\\n特朗普当天在美国印第安纳州首府印第安纳波利斯举行的美国全国步枪协会年会上说，《武器贸易条约》是一个“严重误导的条约”，美国将撤销在该条约上的签字，联合国将很快收到美国正式拒绝该条约的通知',\n",
       " '']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.split(\"。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_sentences = text.split(\"。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_all_sentences = []\n",
    "said_similar_shows = {}\n",
    "for _, i in enumerate(all_sentences):\n",
    "    flag = False\n",
    "    for j in said_list:\n",
    "        if j in i:\n",
    "            valid_all_sentences.append(i)\n",
    "            said_similar_shows[len(valid_all_sentences)-1] = j\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['新华社华盛顿4月26日电 美国总统特朗普26日表示，美国将撤销在《武器贸易条约》上的签字',\n",
       " '\\n\\n特朗普当天在美国印第安纳州首府印第安纳波利斯举行的美国全国步枪协会年会上说，《武器贸易条约》是一个“严重误导的条约”，美国将撤销在该条约上的签字，联合国将很快收到美国正式拒绝该条约的通知']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_all_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\CHRIST~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.910 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "l2 = [str(i) for i in posseg.cut(valid_all_sentences[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['特朗普']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i[:-3] for i in l2 if \"nr\" in i]#find speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'，美国将撤销在《武器贸易条约》上的签字'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_all_sentences[0][valid_all_sentences[0].find(said_similar_shows[0])+len(said_similar_shows[0]) : ]# find the claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "claim0 = valid_all_sentences[0][valid_all_sentences[0].find(said_similar_shows[0])+len(said_similar_shows[0]) : ]#assume claim in right\n",
    "def claim_in_right_and_del_first_few_words(string_input, find_area=5):\n",
    "    \"\"\"\n",
    "    input: string_input - string, find_area - int \n",
    "    output: return string start from \"，\" as found in first few words of string_input\n",
    "    \"\"\"\n",
    "    if find_area > len(string_input):\n",
    "        return(\"Error, find_area too long\")\n",
    "    if \"，\" in string_input[:find_area]:\n",
    "        return string_input[string_input.find(\"，\")+1: ]\n",
    "    else:\n",
    "        return string_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'美国将撤销在《武器贸易条约》上的签字'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del_first_few_words(claim0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from jieba import posseg\n",
    "import pandas as pd\n",
    "\n",
    "def claim_in_right_and_del_first_few_words(string_input, find_area=5):\n",
    "    \"\"\"\n",
    "    input: string_input - string, find_area - int \n",
    "    output: return string start from \"，\" as found in first few words of string_input\n",
    "    \"\"\"\n",
    "    if find_area > len(string_input):\n",
    "        return(\"Error, find_area too long\")\n",
    "    if \"，\" in string_input[:find_area]:\n",
    "        return string_input[string_input.find(\"，\")+1: ]\n",
    "    else:\n",
    "        return string_input\n",
    "\n",
    "def seperate_texts(string_input):\n",
    "    all_sentences = string_input.split(\"。\")\n",
    "    \n",
    "    valid_all_sentences = []# store all sentences with \"said\" - \"said\" means all similar said words\n",
    "    said_similar_shows = {}#store first said similar word\n",
    "    for _, i in enumerate(all_sentences):\n",
    "        for j in said_list:\n",
    "            if j in i:\n",
    "                valid_all_sentences.append(i)\n",
    "                said_similar_shows[len(valid_all_sentences)-1] = j\n",
    "                continue\n",
    "\n",
    "    length = len(valid_all_sentences)\n",
    "    if length == 0:\n",
    "        return(\"None claim found!\")\n",
    "    \n",
    "    speaker = [0]*length\n",
    "    claim = [0]*length\n",
    "    for i in range(length):\n",
    "        l2 = [str(i) for i in posseg.cut(valid_all_sentences[i])]\n",
    "        if len([i[:-3] for i in l2 if \"nr\" in i]) == 0:\n",
    "            speaker[i] = \"as_you_know\"#if none exist, give \"as you know\"\n",
    "        else:\n",
    "            speaker[i] = [i[:-3] for i in l2 if \"nr\" in i][0]#find speaker, only retain first match\n",
    "        \n",
    "        claim[i] = valid_all_sentences[i][valid_all_sentences[i].find(said_similar_shows[i])+len(said_similar_shows[i]) : ]#assume claims in right\n",
    "        claim[i] = claim_in_right_and_del_first_few_words(claim[i])\n",
    "    \n",
    "    DF_speaker_claim = pd.DataFrame({\"speaker\": speaker, \"claim\": claim})\n",
    "    return DF_speaker_claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'小贤说，小贤就有这样一个室友，他和一个女孩生活在同一幢公寓的两个套房中，可惜一个总是向左走，另一个总是……坐电梯。子乔说，人家是陈圆圆，你？（瞄胸）陈，扁，扁！。展博说，人们用八个字来形容她说，静若处子，动若疯兔。子乔说，你的眸，清澈动人，你的手，温柔细腻，你的心，晶莹剔透;。刘美嘉说，你的臂，孔武有力，你的胸，宽广伟岸，你的皮，刀枪不入...。胡一菲说，我和展博以前是连体婴儿，两岁前我们俩脑子还长在一块呢。小贤说，对，然后医生刀一快，把脑子全给了展博。展博说，先来五份“强暴鸡米花”！。宛瑜（对服务员）说，那我们要五份“强暴鸡米花”。胡一菲说，两位神童，人家那是“劲暴鸡米花”。展博说，哦，是吗，改名啦？。子乔说，那时候天还是蓝的，水也是绿的，鸡鸭是没有禽流感的，猪肉是可以放心吃的。那时候照像是要穿衣服的，欠债是要还钱的，丈母娘嫁闺女是不图你房子的，孩子的爸爸...也是明确的。子乔说，那还是我读高中的时候，有一天我梦到自已在考试，后来我就一下子惊醒了，更恐怖的事情发生了，原来我真的在考试！。李关谷说，《无极》不是爱情片吗？。子乔说，哈！一看你就不懂电影！...《无极》是恐怖片！。丽莎说，是你！曾小贤！。曾小贤说，你认识我？。'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = pd.read_table(\"love_apartment.txt\", encoding = \"gbk\")\n",
    "\n",
    "text0 = \"\".join(list(text[\"claims\"]))\n",
    "\n",
    "text0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>小贤就有这样一个室友，他和一个女孩生活在同一幢公寓的两个套房中，可惜一个总是向左走，另一个总...</td>\n",
       "      <td>小贤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>人家是陈圆圆，你？（瞄胸）陈，扁，扁！</td>\n",
       "      <td>子乔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>静若处子，动若疯兔</td>\n",
       "      <td>展博</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>人们用八个字来形容她说，静若处子，动若疯兔</td>\n",
       "      <td>展博</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>你的眸，清澈动人，你的手，温柔细腻，你的心，晶莹剔透;</td>\n",
       "      <td>子乔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>你的臂，孔武有力，你的胸，宽广伟岸，你的皮，刀枪不入...</td>\n",
       "      <td>刘美嘉</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>我和展博以前是连体婴儿，两岁前我们俩脑子还长在一块呢</td>\n",
       "      <td>胡一菲</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>对，然后医生刀一快，把脑子全给了展博</td>\n",
       "      <td>小贤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>先来五份“强暴鸡米花”！</td>\n",
       "      <td>展博</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>那我们要五份“强暴鸡米花”</td>\n",
       "      <td>宛瑜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>两位神童，人家那是“劲暴鸡米花”</td>\n",
       "      <td>胡一菲</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>哦，是吗，改名啦？</td>\n",
       "      <td>展博</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>那时候天还是蓝的，水也是绿的，鸡鸭是没有禽流感的，猪肉是可以放心吃的</td>\n",
       "      <td>子乔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>那还是我读高中的时候，有一天我梦到自已在考试，后来我就一下子惊醒了，更恐怖的事情发生了，原来...</td>\n",
       "      <td>子乔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>《无极》不是爱情片吗？</td>\n",
       "      <td>李关谷</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>哈！一看你就不懂电影！...《无极》是恐怖片！</td>\n",
       "      <td>子乔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>是你！曾小贤！</td>\n",
       "      <td>丽莎/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>你认识我？</td>\n",
       "      <td>曾小贤</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                claim speaker\n",
       "0   小贤就有这样一个室友，他和一个女孩生活在同一幢公寓的两个套房中，可惜一个总是向左走，另一个总...      小贤\n",
       "1                                 人家是陈圆圆，你？（瞄胸）陈，扁，扁！      子乔\n",
       "2                                           静若处子，动若疯兔      展博\n",
       "3                               人们用八个字来形容她说，静若处子，动若疯兔      展博\n",
       "4                         你的眸，清澈动人，你的手，温柔细腻，你的心，晶莹剔透;      子乔\n",
       "5                       你的臂，孔武有力，你的胸，宽广伟岸，你的皮，刀枪不入...     刘美嘉\n",
       "6                          我和展博以前是连体婴儿，两岁前我们俩脑子还长在一块呢     胡一菲\n",
       "7                                  对，然后医生刀一快，把脑子全给了展博      小贤\n",
       "8                                        先来五份“强暴鸡米花”！      展博\n",
       "9                                       那我们要五份“强暴鸡米花”      宛瑜\n",
       "10                                   两位神童，人家那是“劲暴鸡米花”     胡一菲\n",
       "11                                          哦，是吗，改名啦？      展博\n",
       "12                 那时候天还是蓝的，水也是绿的，鸡鸭是没有禽流感的，猪肉是可以放心吃的      子乔\n",
       "13  那还是我读高中的时候，有一天我梦到自已在考试，后来我就一下子惊醒了，更恐怖的事情发生了，原来...      子乔\n",
       "14                                        《无极》不是爱情片吗？     李关谷\n",
       "15                            哈！一看你就不懂电影！...《无极》是恐怖片！      子乔\n",
       "16                                            是你！曾小贤！     丽莎/\n",
       "17                                              你认识我？     曾小贤"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seperate_texts(text0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 补充匹配：话+“，”+人名+“说”+“。”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from jieba import posseg\n",
    "import pandas as pd\n",
    "\n",
    "def claim_in_right_and_del_first_few_words(string_input, find_area=6, said_similar=\"说\"):\n",
    "    \"\"\"\n",
    "    input: string_input - string, find_area - int \n",
    "    output: return string start from \"，\" as found in first few words of string_input\n",
    "    \"\"\"\n",
    "    if find_area > len(string_input):\n",
    "        return(\"Error, find_area too long\")\n",
    "    if said_similar in string_input[:find_area] and \"，\" in string_input[:find_area]:#还有以：隔断的，此处未考虑到\n",
    "        return string_input[string_input.find(\"，\")+1: ]\n",
    "    if said_similar in string_input[-find_area : ] and \"，\" in string_input[-find_area : ]:#########update here\n",
    "        return string_input[::-1][string_input[::-1].find(\"，\")+1: ][::-1]\n",
    "    else:\n",
    "        return string_input\n",
    "\n",
    "def seperate_texts_update(string_input):\n",
    "    all_sentences = string_input.split(\"。\")#句子还有以！？......结尾的，此处未考虑到\n",
    "    \n",
    "    valid_all_sentences = []# store all sentences with \"said\" - \"said\" means all similar said words\n",
    "    said_similar_shows = {}#store first said similar word\n",
    "    for _, i in enumerate(all_sentences):\n",
    "        for j in said_list:\n",
    "            if j in i:\n",
    "                valid_all_sentences.append(i)\n",
    "                said_similar_shows[len(valid_all_sentences)-1] = j\n",
    "                continue\n",
    "\n",
    "    length = len(valid_all_sentences)\n",
    "    if length == 0:\n",
    "        return(\"None claim found!\")\n",
    "    \n",
    "    speaker = [0]*length\n",
    "    claim = [0]*length\n",
    "    for i in range(length):\n",
    "        l2 = [str(i) for i in posseg.cut(valid_all_sentences[i])]\n",
    "        if len([i[:-3] for i in l2 if \"nr\" in i]) == 0:\n",
    "            speaker[i] = \"as_you_know\"#if none exist, give \"as you know\"\n",
    "        else:\n",
    "            speaker[i] = [i[:-3] for i in l2 if \"nr\" in i][0]#find speaker, only retain first match\n",
    "        \n",
    "        #claim[i] = valid_all_sentences[i][valid_all_sentences[i].find(said_similar_shows[i])+len(said_similar_shows[i]) : ]#assume claims in right\n",
    "        claim[i] = claim_in_right_and_del_first_few_words(valid_all_sentences[i], said_similar=said_similar_shows[i])\n",
    "    \n",
    "    DF_speaker_claim = pd.DataFrame({\"speaker\": speaker, \"claim\": claim})\n",
    "    return DF_speaker_claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'子乔说，我也想找一个可以把我的头像印到货币上去的地方。不难啊，你找个印冥钞的地方不就可以了吗，刘美嘉说。子乔说，在我们男人的世界里，还是强人如云，縗人如星的。可我放眼望去，万里无云，满天繁星，张一菲说。李关谷说，有一天，小鸭子遇到了四阿哥。“你无情，你残酷，你无理取闹！”，尔康说。唐纳德说，“那你就不无情，不残酷，不无理取闹？”。'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = pd.read_table(\"love_apartment2.txt\", encoding = \"gbk\")\n",
    "\n",
    "text0 = \"\".join(list(text[\"claims\"]))\n",
    "\n",
    "text0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>我也想找一个可以把我的头像印到货币上去的地方</td>\n",
       "      <td>子乔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>不难啊，你找个印冥钞的地方不就可以了吗</td>\n",
       "      <td>刘美嘉</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>在我们男人的世界里，还是强人如云，縗人如星的</td>\n",
       "      <td>子乔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>可我放眼望去，万里无云，满天繁星</td>\n",
       "      <td>张一菲</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>有一天，小鸭子遇到了四阿哥</td>\n",
       "      <td>李关谷</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>“你无情，你残酷，你无理取闹！”</td>\n",
       "      <td>尔康</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>“那你就不无情，不残酷，不无理取闹？”</td>\n",
       "      <td>唐纳德</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    claim speaker\n",
       "0  我也想找一个可以把我的头像印到货币上去的地方      子乔\n",
       "1     不难啊，你找个印冥钞的地方不就可以了吗     刘美嘉\n",
       "2  在我们男人的世界里，还是强人如云，縗人如星的      子乔\n",
       "3        可我放眼望去，万里无云，满天繁星     张一菲\n",
       "4           有一天，小鸭子遇到了四阿哥     李关谷\n",
       "5        “你无情，你残酷，你无理取闹！”      尔康\n",
       "6     “那你就不无情，不残酷，不无理取闹？”     唐纳德"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seperate_texts_update(text0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 尚未匹配：话1+人名+“说”+话2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
