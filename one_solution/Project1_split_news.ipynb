{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#封装成函数\" data-toc-modified-id=\"封装成函数-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>封装成函数</a></span><ul class=\"toc-item\"><li><span><a href=\"#read-news\" data-toc-modified-id=\"read-news-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>read news</a></span></li><li><span><a href=\"#read-similars-of-&quot;say&quot;\" data-toc-modified-id=\"read-similars-of-&quot;say&quot;-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>read similars of \"say\"</a></span></li><li><span><a href=\"#split-one-piece-of-news\" data-toc-modified-id=\"split-one-piece-of-news-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>split one piece of news</a></span><ul class=\"toc-item\"><li><span><a href=\"#load-LTP\" data-toc-modified-id=\"load-LTP-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>load LTP</a></span></li><li><span><a href=\"#split-each-news\" data-toc-modified-id=\"split-each-news-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>split each news</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 封装成函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Reference1 - other solutions](https://github.com/enix223/nlp-course/blob/master/notebooks/news_options.ipynb)\n",
    "\n",
    "[Reference2 - pyltp](https://pyltp.readthedocs.io/zh_CN/latest/api.html#id13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "NEWS_DATA_PATH = 'mydata/sqlResult_1558435.csv'\n",
    "df = pd.read_csv(NEWS_DATA_PATH, encoding='gb18030')\n",
    "contents = df[~df['content'].isnull()]['content']\n",
    "#use contents (list) as input of the function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read similars of \"say\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "say_similar = pd.read_csv(\"similar_said.csv\", encoding = \"gbk\")\n",
    "said_list = list(say_similar['similar_of_said'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split one piece of news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load LTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import jieba\n",
    "import pyltp\n",
    "import pandas as pd\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "LTP_DATA_DIR = 'mydata/ltp_data_v3.4.0'  # ltp模型目录的路径\n",
    "srl_model_path = os.path.join(LTP_DATA_DIR, 'pisrl.model')\n",
    "\n",
    "segmentor = pyltp.Segmentor()\n",
    "segmentor.load(cws_model_path)\n",
    "\n",
    "postagger = pyltp.Postagger()\n",
    "postagger.load(pos_model_path)\n",
    "\n",
    "recognizer = pyltp.NamedEntityRecognizer()\n",
    "recognizer.load(ner_model_path)\n",
    "\n",
    "parser = pyltp.Parser()\n",
    "parser.load(par_model_path)\n",
    "\n",
    "labeller = pyltp.SementicRoleLabeller() # 初始化实例\n",
    "labeller.load(srl_model_path)  # 加载模型\n",
    "\n",
    "print(\"########################end load#################################\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split each news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "news = contents[96]\n",
    "words = segmentor.segment(news.replace('\\r\\n', ''))\n",
    "postags = postagger.postag(words)\n",
    "netags = recognizer.recognize(words, postags)\n",
    "\n",
    "#find \"say\"\n",
    "say_positions = [(w, i) for i, w in enumerate(words) if w in said_list]\n",
    "\n",
    "#find entities who say that\n",
    "all_names_positions = [(i, tag) for i, tag in enumerate(netags) if 'Nh' in tag]\n",
    "all_names = [(words[name[0]], name[0]) for name in all_names_positions]\n",
    "names = set(map(lambda x: x[0], all_names))\n",
    "\n",
    "#find each sentence(background+saying+entity_say) in one group of words(split by \\r\\n)\n",
    "arcs = parser.parse(words, postags)\n",
    "\n",
    "#extract from name\n",
    "def get_all_words_related_to(index):\n",
    "    return [words[i] for i, arc in enumerate(arcs) if arc.head == index]\n",
    "\n",
    "candidates = [(name, arcs[name[1]].relation, arcs[name[1]].head) \n",
    "              for name in all_names if arcs[name[1]].relation == 'SBV']\n",
    "\n",
    "def is_sentence_end(w):\n",
    "    return w in [\"。\", \"!\", \"！\"]\n",
    "\n",
    "#whole extract\n",
    "options = []\n",
    "for say_word, pos in say_positions:\n",
    "    option = {'say': say_word}\n",
    "    # Get the name who say the words\n",
    "    for i in range(pos, 0, -1):\n",
    "        w = words[i]\n",
    "        if w in names:\n",
    "            option['name'] = w\n",
    "            break\n",
    "    \n",
    "    sentence = ''\n",
    "    for w in words[pos + 1:]:\n",
    "        sentence += w\n",
    "        if is_sentence_end(w):\n",
    "            option['sentence'] = sentence\n",
    "            break\n",
    "    \n",
    "    options.append(option)\n",
    "    \n",
    "print(option)#option(dict) include \"name\", \"say\" and \"sentence\"    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
